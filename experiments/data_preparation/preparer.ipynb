{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c99d37f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00cd24f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_outsiders = \"/export/data_ml4ds/NextProcurement/Junio_2025/pliegosPlace/red_data_outsiders_2024_conTitleCPVLink_chunks\"\n",
    "path_insiders = \"/export/data_ml4ds/NextProcurement/Junio_2025/pliegosPlace/red_data_insiders_2024_conTitleCPVLink_chunks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d75b517",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_insiders = pd.read_parquet(path_insiders)\n",
    "df_outsiders = pd.read_parquet(path_outsiders)\n",
    "\n",
    "# make id unique\n",
    "df_insiders[\"id\"] = \"I\" + df_insiders[\"id\"].astype(str)\n",
    "df_outsiders[\"id\"] = \"O\" + df_outsiders[\"id\"].astype(str)\n",
    "\n",
    "df_in_out = pd.concat([df_insiders, df_outsiders], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3084db6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['place_id', 'link',\n",
       "       'ContractFolderStatus.ProcurementProject.RequiredCommodityClassification.ItemClassificationCode',\n",
       "       'title', 'url', 'id', 'resultado_tecnico', 'path_tecnico',\n",
       "       'resultado_administrativo', 'path_administrativo', 'texto_tecnico',\n",
       "       'texto_administrativo'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_in_out.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39d08a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "35340\n",
      "114600\n"
     ]
    }
   ],
   "source": [
    "print(df_in_out[\"id\"].duplicated().sum())\n",
    "assert len(df_in_out) == len(df_in_out[\"id\"].unique()) == len(df_insiders) + len(df_outsiders)\n",
    "print(len(df_outsiders))\n",
    "print(len(df_insiders))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85b4174",
   "metadata": {},
   "source": [
    "# Objective extractor experiments\n",
    "\n",
    "We get a random sample of 500 outsiders + 500 insiders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83a779eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERR = \"[ERROR: PDF sin texto extraíble (posiblemente escaneado)]\"\n",
    "\n",
    "text_col = df_in_out[\"texto_tecnico\"].astype(\"string\").fillna(\"\")\n",
    "id_str   = df_in_out[\"id\"].astype(\"string\").fillna(\"\")\n",
    "\n",
    "mask_I = id_str.str.startswith(\"I\")\n",
    "mask_O = id_str.str.startswith(\"O\")\n",
    "mask_ok_text = ~text_col.str.strip().eq(ERR)\n",
    "\n",
    "# rows that are entirely control chars / whitespace (at least one char)\n",
    "mask_all_control = ~text_col.str.fullmatch(r'[\\x00-\\x1F\\x7F\\s]+', na=False)\n",
    "\n",
    "# rows whose title column is not nan or empty after stripping\n",
    "title_col = df_in_out[\"title\"].astype(\"string\").fillna(\"\")\n",
    "mask_title_ok = ~title_col.str.strip().eq(\"\")\n",
    "\n",
    "df_I = df_in_out.loc[mask_I & mask_all_control & mask_ok_text & mask_title_ok]\n",
    "df_O = df_in_out.loc[mask_O & mask_all_control & mask_ok_text & mask_title_ok]\n",
    "\n",
    "df_sample = pd.concat([\n",
    "    (df_I.sample(min(500, len(df_I)), random_state=42) if len(df_I) else df_I.head(0)),\n",
    "    (df_O.sample(min(500, len(df_O)), random_state=42) if len(df_O) else df_O.head(0)),\n",
    "], ignore_index=True)\n",
    "\n",
    "\n",
    "path_save = \"/export/data_ml4ds/NextProcurement/pruebas_oct_2025/objective_extractor/data/insiders_outsiders_500_500.parquet\"\n",
    "\n",
    "os.makedirs(pathlib.Path(path_save).parent, exist_ok=True)\n",
    "df_sample.to_parquet(path_save, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17f1fcc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Elaboración y redacción del Plan de Movilidad ...\n",
       "1      Contratación del suministro de flores y planta...\n",
       "2      Contratación del servicio de Análisis Clínicos...\n",
       "3      Objeto del contrato: La finalidad del presente...\n",
       "4      CEMILVET - Suministro de instalación de 2 auto...\n",
       "                             ...                        \n",
       "995    MRU Serveis de redacció de l'estudi de seguret...\n",
       "996          Servei de menjador de l'Escola de Rellinars\n",
       "997    Suministros y servicios para la protección y c...\n",
       "998    l’adjudicació de la prestació de suport al ser...\n",
       "999    Acord Marc del subministrament de Pròtesis de ...\n",
       "Name: title, Length: 1000, dtype: string"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.title\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8f7edf",
   "metadata": {},
   "source": [
    "# Divide by CPV and get CPV5 and CPV8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f143b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "def safe_parse_possible_array_string(item):\n",
    "    \"\"\"Fix format like array(['[50300000, 50330000]']) and ignore 'nan' strings.\"\"\"\n",
    "    if isinstance(item, np.ndarray) and len(item) == 1:\n",
    "        string = item[0]\n",
    "        if isinstance(string, str) and string.strip().lower() == \"nan\":\n",
    "            return []  # Treat as empty\n",
    "        try:\n",
    "            parsed = ast.literal_eval(string)\n",
    "            if isinstance(parsed, list):\n",
    "                return parsed\n",
    "        except (ValueError, SyntaxError):\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def extract_cpv_depth(code):\n",
    "    \"\"\"Extracts CPV depth from a single CPV code if valid.\"\"\"\n",
    "    try:\n",
    "        code_float = float(code)\n",
    "        code_str = str(int(code_float))\n",
    "        return len(code_str.rstrip('0'))\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "def analyze_cpv_depths(df, column='cpv'):\n",
    "    depths = []\n",
    "    format_issues = []\n",
    "    nan_count = 0\n",
    "    total = 0\n",
    "\n",
    "    for item in df[column]:\n",
    "        \n",
    "        if isinstance(item, np.ndarray) and len(item) == 1 and str(item[0]).strip().lower() == \"nan\":\n",
    "            nan_count += 1\n",
    "            continue\n",
    "        \n",
    "        if isinstance(item, list):\n",
    "            if len(item) == 0:\n",
    "                nan_count += 1\n",
    "                continue\n",
    "            for code in item:\n",
    "                total += 1\n",
    "                depth = extract_cpv_depth(code)\n",
    "                if depth is not None:\n",
    "                    depths.append(depth)\n",
    "                else:\n",
    "                    format_issues.append(code)\n",
    "\n",
    "        elif pd.isna(item):\n",
    "            nan_count += 1\n",
    "\n",
    "        else:\n",
    "            # Try to fix malformed numpy array string like: array(['[50300000, 50330000]'])\n",
    "            recovered_list = safe_parse_possible_array_string(item)\n",
    "            if recovered_list:\n",
    "                for code in recovered_list:\n",
    "                    total += 1\n",
    "                    depth = extract_cpv_depth(code)\n",
    "                    if depth is not None:\n",
    "                        depths.append(depth)\n",
    "                    else:\n",
    "                        format_issues.append(code)\n",
    "            else:\n",
    "                total += 1\n",
    "                depth = extract_cpv_depth(item)\n",
    "                if depth is not None:\n",
    "                    depths.append(depth)\n",
    "                else:\n",
    "                    format_issues.append(item)\n",
    "\n",
    "    print(f\"Total CPV codes processed: {total}\")\n",
    "    print(f\"Format issues: {len(format_issues)}\")\n",
    "    print(f\"NaNs or empty lists: {nan_count}\")\n",
    "    print(f\"Valid CPV codes with depth: {len(depths)}\")\n",
    "\n",
    "    depth_counts = pd.Series(depths).value_counts().sort_index()\n",
    "    return depth_counts, format_issues, nan_count, total\n",
    "\n",
    "depth_counts, bad_cpvs, nan_count, total_cpvs = analyze_cpv_depths(df)\n",
    "\n",
    "print(depth_counts)\n",
    "print(\"\\nExamples of format issues:\")\n",
    "print(bad_cpvs[:10])  # first 10 malformed entries\n",
    "\n",
    "def format_latex_count_and_percentage_with_nans(depth_counts, nan_count, total_rows):\n",
    "    full_counts = depth_counts.copy()\n",
    "    full_counts[\"NaN / empty\"] = nan_count  # Add nan count as its own category\n",
    "\n",
    "    formatted = []\n",
    "    for depth, count in full_counts.items():\n",
    "        percent = 100 * count / total_rows\n",
    "        count_str = f\"{count:,}\".replace(\",\", r\"\\,\")\n",
    "        formatted.append((str(depth), f\"\\\\({count_str}\\\\) ({percent:.2f}\\\\%)\"))\n",
    "\n",
    "    return pd.DataFrame(formatted, columns=[\"CPV Code Depth\", \"Count (Percentage)\"])\n",
    "\n",
    "depth_table = format_latex_count_and_percentage_with_nans(depth_counts, nan_count, total_cpvs)\n",
    "\n",
    "print(depth_table.to_latex(index=False, escape=False))\n",
    "\n",
    "# check sum of depth_counts and nan_count\n",
    "total_count = depth_counts.sum() + nan_count\n",
    "print(f\"Total count of CPV codes (including NaNs): {total_count} (should match total rows in DataFrame: {len(df)})\")\n",
    "assert total_count >= len(df), \"Total count of CPV codes (including NaNs) should be greater than or equal to total rows in DataFrame.\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
